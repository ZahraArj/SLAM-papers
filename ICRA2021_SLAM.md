# References - ICRA 2021

<!---
Started to write on June 1 2021
Jungwon
-->


### General Information
- [Full Program](https://ras.papercept.net/conferences/conferences/ICRA21/program/ICRA21_ProgramAtAGlanceWeb.html)
- [ICRA 2021 Workshop and Tutorial Schedule and Information](https://www.ieee-icra.org/workshop.html)
<br/>
<br/>


### Workshops
The full list of workshops are available at [https://www.ieee-icra.org/workshop.html].
- [Opportunities and Challenges with Autonomous Racing](https://linklab-uva.github.io/icra-autonomous-racing/)
- [Robust Perception For Autonomous Field Robots in Challenging Environments](http://robustperception.net/)
- [Visual-Inertial Navigation Systems](http://copland.udel.edu/~ghuang/icra21-vins-workshop/)
- [Resilient and Long-Term Autonomy for Aerial Robotic Systems](https://www.aerial-robotics-workshop.com/agenda.html)
  - The flying Cartographer: Using a graph SLAM method for a long-term UAV navigation
- [First International Workshop on Perception and Action in Highly-Dynamic Environments](https://uzh-rpg.github.io/PADE-ICRA2021/)
<br/>
<br/>


### Best papers
- [CodeVIO: Visual-Inertial Odometry with Learned Optimizable Dense Depth](https://arxiv.org/abs/2012.10133)
- [Interval-Based Visual-LiDAR Sensor Fusion](https://www.researchgate.net/publication/349141103_Interval-Based_Visual-LiDAR_Sensor_Fusion)
- [OmniDet: Surround View Cameras Based Multi-Task Visual Perception Network for Autonomous Driving](https://arxiv.org/abs/2102.07448)
- [Unsupervised Learning of Lidar Features for Use in a Probabilistic Trajectory Estimator](https://arxiv.org/abs/2102.11261)
- [VIODE: A Simulated Dataset to Address the Challenges of Visual-Inertial Odometry in Dynamic Environments](https://arxiv.org/abs/2102.05965)
<br/>
<br/>


### Odometry/SLAM (LiDAR only)
- [PSF-LO: Parameterized Semantic Features Based Lidar Odometry](https://arxiv.org/abs/2010.13355)
- [Self-supervised Learning of LiDAR Odometry for Robotic Applications](https://arxiv.org/abs/2011.05418)
- ENCODE: A dEep poiNt Cloud ODometry NEtwork
- Automatic Hyper-Parameter Tuning for Black-Box LiDAR Odometry
- R-LOAM: Improving LiDAR Odometry and Mapping with Point-To-Mesh Features of a Known 3D Reference Object
<br/>

- [MULLS: Versatile LiDAR SLAM Via Multi-Metric Linear Least Square](https://github.com/YuePanEdward/MULLS)
- [Dynamic Object Aware LiDAR SLAM Based on Automatic Generation of Training Data](https://arxiv.org/abs/2104.03657)
- [LiTAMIN2: Ultra Light LiDAR-Based SLAM Using Geometric Approximation Applied with KL-Divergence](https://arxiv.org/abs/2103.00784)
- [Intensity-SLAM: Intensity Assisted Localization and Mapping for Large Scale Environment](https://arxiv.org/abs/2102.03798)
- SA-LOAM: Semantic-Aided LiDAR SLAM with Loop Closure
  - https://kxhit.github.io/
- Inertial Aided 3D LiDAR SLAM with Hybrid Geometric Primitives in Large-Scale Environments
- [UPSLAM: Union of Panoramas SLAM](https://arxiv.org/abs/2101.00585)
- PocoNet: SLAM-Oriented 3D LiDAR Point Cloud Online Compression Network
- [LoLa-SLAM: Low-Latency LiDAR SLAM Using Continuous Scan Slicing](https://ieeexplore.ieee.org/document/9359468)
- [Greedy-Based Feature Selection for Efficient LiDAR SLAM](https://arxiv.org/abs/2103.13090?context=cs)
- 2D Laser SLAM with Closed Shape Features: Fourier Series Parameterization and Submap Joining
<br/>
<br/>


### Odometry/SLAM (Vision only)
- Deep Online Correction for Monocular Visual Odometry
<br/>

- [OV2SLAM : A Fully Online and Versatile Visual SLAM for Real-Time Applications](https://github.com/ov2slam/ov2slam)
- [Semantic SLAM with Autonomous Object-Level Data Association](https://arxiv.org/pdf/2011.10625.pdf)
- [Asynchronous Multi-View SLAM](https://arxiv.org/abs/2101.06562)
- Distributed Variable-Baseline Stereo SLAM from Two UAVs
- SD-DefSLAM: Semi-Direct Monocular SLAM for Deformable and Intracorporeal Scenes
- TT-SLAM: Dense Monocular SLAM for Planar Environments
- Hybrid Bird's-Eye Edge Based Semantic Visual SLAM for Automated Valet Parking
- A Front-End for Dense Monocular SLAM Using a Learned Outlier Mask Prior
- Avoiding Degeneracy for Monocular Visual SLAM with Point and Line Features
- DefSLAM: Tracking and Mapping of Deforming Scenes from Monocular Sequences
- DOT: Dynamic Object Tracking for Visual SLAM
<br/>
<br/>


### Odometry/SLAM (LiDAR + Vision)
- [CamVox: A Low-Cost and Accurate Lidar-Assisted Visual SLAM System](https://arxiv.org/abs/2011.11357)
- Visual-Laser-Inertial SLAM Using a Compact 3D Scanner for Confined Space
<br/>
<br/>


### Odometry/SLAM (LiDAR + Inertial)
- LIRO: Tightly Coupled Lidar-Inertia-Ranging Odometry
- KFS-LIO: Key-Feature Selection for Lightweight Lidar Inertial Odometry
- FAST-LIO: A Fast, Robust LiDAR-Inertial Odometry Package by Tightly-Coupled Iterated Kalman Filter
<br/>
<br/>


### Odometry/SLAM (Vision + Inertial)
- [CodeVIO: Visual-Inertial Odometry with Learned Optimizable Dense Depth](https://arxiv.org/abs/2012.10133)
- Range-Visual-Inertial Odometry: Scale Observability without Excitation
- [VIODE: A Simulated Dataset to Address the Challenges of Visual-Inertial Odometry in Dynamic Environments](https://arxiv.org/abs/2102.05965)
- Collaborative Visual Inertial SLAM for Multiple Smart Phones
- Cooperative Visual-Inertial Odometry
- Bidirectional Trajectory Computation for Odometer-Aided Visual-Inertial SLAM
- Optimization-Based Visual-Inertial SLAM Tightly Coupled with Raw GNSS Measurements
- Revisiting Visual-Inertial Structure-From-Motion for Odometry and SLAM Initialization
- Direct Sparse Stereo Visual-Inertial Global Odometry
- Bidirectional Trajectory Computation for Odometer-Aided Visual-Inertial SLAM
<br/>
<br/>


### Odometry/SLAM (LiDAR + Vision + Inertial)
- LVI-SAM: Tightly-Coupled Lidar-Visual-Inertial Odometry Via Smoothing and Mapping
- Unified Multi-Modal Landmark Tracking for Tightly Coupled Lidar-Visual-Inertial Odometry
<br/>
<br/>


### Odometry/SLAM (RGB-D)
- Multi-Parameter Optimization for a Robust RGB-D SLAM System
- RGB-D SLAM with Structural Regularities
- [Towards Real-Time Semantic RGB-D SLAM in Dynamic Environments](https://arxiv.org/pdf/2104.01316.pdf)
<br/>
<br/>


### Odometry/SLAM, but not categorized yet
- [LatentSLAM: Unsupervised Multi-Sensor Representation Learning for Localization and Mapping](https://arxiv.org/abs/2105.03265)
- Tactile SLAM: Real-Time Inference of Shape and Pose from Planar Pushing
- ManhattanSLAM: Robust Planar Tracking and Mapping Leveraging Mixture of Manhattan Frames
- Robust Underwater Visual SLAM Fusing Acoustic Sensing
- Distributed Client-Server Optimization for SLAM with Limited On-Device Resources
- Invariant EKF Based 2D Active SLAM with Exploration Task
- Compositional and Scalable Object SLAM
- Markov Parallel Tracking and Mapping for Probabilistic SLAM
- Multi-Session Underwater Pose-Graph SLAM Using Inter-Session Opti-Acoustic Two-View Factor
- Online Range-Based SLAM Using B-Spline Surfaces
- RigidFusion: Robot Localisation and Mapping in Environments with Large Dynamic Rigid Objects
- Connecting Semantic Building Information Models and Robotics: An Application to 2D LiDAR-Based Localization
- CAROM - Vehicle Localization and Traffic Scene Reconstruction from Monocular Cameras on Road Infrastructures
- Semantic Reinforced Attention Learning for Visual Place Recognition
<br/>
<br/>


### Segmentation (2D) 
- [Real-Time Semantic Segmentation with Fast Attention](https://arxiv.org/abs/2007.03815)
- [YolactEdge: Real-Time Instance Segmentation on the Edge](https://arxiv.org/abs/2012.12259)
- [Learning Panoptic Segmentation from Instance Contours](https://arxiv.org/abs/2010.11681)
- GPU-Efficient Dense Convolutional Network for Real-Time Semantic Segmentation
- Target-Targeted Domain Adaptation for Unsupervised Semantic Segmentation
<br/>
<br/>


### Segmentation (3D) 
- [S3Net: 3D LiDAR Sparse Semantic Segmentation Network](https://arxiv.org/abs/2103.08745)
- [Self-Supervised Learning of Lidar Segmentation for Autonomous Indoor Navigation](https://arxiv.org/abs/2012.05897)
- [Lite-HDSeg: LiDAR Semantic Segmentation Using Lite Harmonic Dense Convolutions](https://arxiv.org/abs/2103.08852)
- LiDARNet: A Boundary-Aware Domain Adaptation Model for Point Cloud Semantic Segmentation
- Efficient RGB-D Semantic Segmentation for Indoor Scene Analysis
- [A Benchmark for LiDAR-Based Panoptic Segmentation Based on KITTI](https://arxiv.org/abs/2003.02371)
- Neighborhood Spatial Aggregation Based Efficient Uncertainty Estimation for Point Cloud Semantic Segmentation
<br/>
<br/>


### Object Detection (3D)
- [Ground-Aware Monocular 3D Object Detection for Autonomous Driving](https://arxiv.org/abs/2102.00690)
- MonoSOD: Monocular Salient Object Detection Based on Predicted Depth
<br/>
<br/>


### Depth estimation
- UniFuse: Unidirectional Fusion for 360 Panorama Depth Estimation
- Multimodal Scale Consistency and Awareness for Monocular Self-Supervised Depth Estimation
- Combining Events and Frames Using Recurrent Asynchronous Multimodal Networks for Monocular Depth Prediction
- Self-Supervised Learning for Monocular Depth Estimation on Minimally Invasive Surgery Scenes
- Depth Estimation under Motion with Single Pair Rolling Shutter Stereo Images
- Learning a Geometric Representation for Data-Efficient Depth Estimation Via Gradient Field and Contrastive Loss
- Volumetric Propagation Network: Stereo-LiDAR Fusion for Long-Range Depth Estimation
- PLG-IN: Pluggable Geometric Consistency Loss with Wasserstein Distance in Monocular Depth Estimation
- Bidirectional Attention Network for Monocular Depth Estimation
- Deep Multi-View Depth Estimation with Predicted Uncertainty
- MultiViewStereoNet: Fast Multi-View Stereo Depth Estimation Using Incremental Viewpoint-Compensated Feature Extraction
- Toward Robust and Efficient Online Adaptation for Deep Stereo Depth Estimation
<br/>
<br/>


### Depth completion
- PENet: Towards Precise and Efficient Image Guided Depth Completion
- DenseLiDAR: A Real-Time Pseudo Dense Depth Guided Depth Completion Network
- Robust Monocular Visual-Inertial Depth Completion for Embedded Systems
- Learning Topology from Synthetic Data for Unsupervised Depth Completion
- SelfDeco: Self-Supervised Monocular Depth Completion in Challenging Indoor Environments
- An Adaptive Framework for Learning Unsupervised Depth Completion
- MDANet: Multi-Modal Deep Aggregation Network for Depth Completion
- Stereo-Augmented Depth Completion from a Single RGB-LiDAR Image
- Self-Guided Instance-Aware Network for Depth Completion and Enhancement
- Linear Inverse Problem for Depth Completion with RGB Image and Sparse LIDAR Fusion
<br/>
<br/>



