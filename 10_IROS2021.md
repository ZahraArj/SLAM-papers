# References - IROS 2021

<!---
Started to write on Oct 21 2021
Zahra
-->


## General Information
The full list of workshops are available at:[Link](https://ras.papercept.net/conferences/conferences/IROS21/program/)
<br/>
<br/>


## Workshops
The full list of workshops are available at: [Link](https://ras.papercept.net/conferences/conferences/IROS21/program/IROS21_ProgramAtAGlanceWeb.html#weat1_) 

<br/>
<br/>


## Best papers

<br/>
<br/>


## Odometry/SLAM (LiDAR only)

<br/>

1- [Visual Place Recognition using LiDAR Intensity Information](https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/digiammarino2021iros.pdf) 
* Through a cylindrical projection, we can turn  3D LiDAR data information into a 360◦panoramic range image. As a result, we can apply techniques from visual place recognition to LiDAR intensity data. 
* This paper provides an analysis of how such visual techniques can be with LiDAR data.
* They provide an evaluation on different datasets. 
* They results suggest that this form of place recognition is possible and an effective means for determining loop closures.  
  
2- [F-LOAM: Fast LiDAR Odometry and Mapping](https://arxiv.org/pdf/2107.00822.pdf)  
* Chnaged the optimization stage of LOAM
* Solution to robotic applications with limited computational resources.
* They adopt a non-iterative two-stage distortion compensation method to reduce the computational cost of scan-to-scan match and scan-to-map refinement iterative calculation.
* For each scan input, the edge and planar features are extracted and matched to a local edge map and a local plane map separately, where the local smoothness is also considered for iterative pose optimization.
* Method:  
  - First stage: They firstly assume constant angular velocity and linear velocity during short period to predict the motion and correct the distortion.
  - Second stage: The distortion will be re-computed after the pose estimation process and the re-computed undistorted features will be updated to the final map
  - Can achieve the similar localization accuracy but at much less computational cost.  
 
3- LiDAR-Based Object-Level SLAM for Autonomous Vehicles
* file of Image exist: combining image recognition technology to generate semantically meaningful maps
* In the field of LiDAR SLAM, this potential has not been fully explored
* it proposes a novel **object-level** SLAM system using 3D LiDARs for autonomous vehicles
* Detect and track poles, walls, and parked cars
* Presents how we process the measurement data of three different shapes of objects to build a graph-based optimization system and facilitate the geometric distribution of poles to detect loops.  

4- [LiDAR SLAM with Plane Adjustment for Indoor Environment](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9464638)
* It introduces a new loop closure criterion and present a corresponding detection method based on checking the geometric consistency. It trigger the loop closure if existing planes are revisited, rather than a place is revisite.
* They introduce the forward ICP flow to enable real-time global registration. (LOAM: perform low-frequency global registration). 
  - It tracks planar points from the nth scan to the (n + 1) th scan which generates a smaller number of constraints than the ICP process [22] where the whole (n + 1) th scan is used to find the nearest planar points in the nth scan. 
  
5- [Low-Drift Odometry, Mapping and Ground Segmentation Using a Backpack LiDAR System](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9484780&tag=1)
* Backpack LiDAR system that achieves both real-time and low-drift performance
* Calibration: merge scans from the two laser scanners on a backpack
* Propose a feature extraction method which generalizes a point’s geometrical characteristics as two groups (disjoint, continuous) and three types  (edge, corner, plane). 
 
6- RF-LIO: Removal-First Tightly-Coupled Lidar Inertial Odometry in High Dynamic Environments
* Building on LIO-SAM
* main: Accurate poses even in high dynamic environments
* Adds adaptive multi-resolution range images, tightly-coupled lidar inertial odometry
* First remove moving objects, and then match lidar scan to the submap

7- [What's in My LiDAR Odometry Toolbox?](https://arxiv.org/pdf/2103.09708.pdf)
<br/>
<br/>



